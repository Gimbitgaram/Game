## 20220502 장서현 추가

### MPU6050 센서 필수 위치( 초록색 체크)
모든 손가락 tip 마다 센서 달면 너무 bulk 해지니깐 엄지, 중지, 약지 손가락만 필수로
OpenPose 딥러닝 사용하면 각 point 점을 매칭시켜줌
센서 위치만 받아오는 데이터로 위치 매핑시키고, 나머지 관절은 interpolation

### 대략적인 센서 위치 및 Point
<img src="https://user-images.githubusercontent.com/48125526/166210037-8d352e71-6e39-41bc-a921-2ac0d72237a1.png"  width="400" height="600">

### MPU6050 스펙
<img src="https://www.devicemart.co.kr/data/editor/goods/1/2015/06/1247052_15470881375494.jpg">
MPU 6050은 가속도 데이터(x,y,z 축 방향)과 자이로 데이터(x,y,z -> yaw, pitch, roll) 데이터 반환

### <딥러닝 구현 1>
- 해당 MPU 센서들의 포인트 값들로 딥러닝 거쳐 손 동작의 이미지 출력 (라즈베리파이에서 수행)
- 이미지 생성에 사용된 가속도-자이로 데이터와 함께 일정 프레임별로 데이터 송신 (라즈베리파이에서 수행)

### <딥러닝 구현 2>
- 프레임별 데이터 수신 받아서 (시계열 이미지 데이터 + 가속도-자이로 데이터) 동작 탐지
- 각 동작마다 수행되어야 하는 게임상의 행동에 필요한 데이터 전달 (예를 들어, 뭔가를 던지는 동작은 가속도 센서로부터 계산된 힘을 함께 전달)

### <딥러닝 구현3>
- 사람마다 손 모양이 다르므로, 초반에 얼굴 열화상 측정할 때 특정 frame에 얼굴 가져다대는 것처럼, 손모양 frame 에 손을 일정시간 손을 일치시켜 관절간 거리 등 손 모양 구현에 필요한 파라미터 추출
- 화면상에서 웹캠(노트북) 기반 object tracking 구현 (대략적인 손의 위치 탐지)
- 탐지된 위치에 모델링된 손 모양 입히기
 
### 현동님 Part
- 유니티 게임 상에 메쉬형태(Collider 가능) 로 손 모양 구현 (관절간 위치 데이터 전송? 고려해 봐야 할 문제)
